{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"check_particle_filter.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle filter \n",
    "\n",
    "This Jupyter notebook file imports (and tests) all of the code needed to do the particle filter assignment. Note that the actual code is in the .py files in this directory.\n",
    "\n",
    "You should only have to edit particle_filter.py - you did all the \"simulator\" code in the previous two assignments.\n",
    "\n",
    "Note that, although we use both sensors in this assignment, we'll only use one at a time, and update the particle distribution (importance sampling) before calling a calculate_weights method again.\n",
    "\n",
    "Slides for this assignment: https://docs.google.com/presentation/d/1GVCAWUSUhJiHP6VBi-HusDyZmunQG1mnVlopLhtRGLs/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '.')\n",
    "import numpy as np\n",
    "\n",
    "# These commands will force JN to actually re-load the external file when you re-execute the import command\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particle_filter import ParticleFilter, test_particle_filter_syntax\n",
    "from world_ground_truth import WorldGroundTruth\n",
    "from robot_sensors import RobotSensors\n",
    "from robot_ground_truth import RobotGroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "n_doors = 2\n",
    "n_bins = 10\n",
    "n_samples = 100\n",
    "world_ground_truth = WorldGroundTruth()\n",
    "world_ground_truth.random_door_placement(n_doors, n_bins)\n",
    "robot_ground_truth = RobotGroundTruth()\n",
    "robot_sensor = RobotSensors()\n",
    "particle_filter = ParticleFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syntax check 1, reset probabilities\n",
    "particle_filter.reset_particles(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syntax check 2, update move\n",
    "particle_filter.update_particles_move_continuous(robot_ground_truth, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syntax checks 3 and 4 - the two different sensor readings\n",
    "particle_filter.calculate_weights_door_sensor_reading(world_ground_truth, robot_sensor, True)\n",
    "if np.isclose(np.max(particle_filter.weights), np.min(particle_filter.weights)):\n",
    "    print(f\"Possible error: The weights should not all be the same\")\n",
    "\n",
    "particle_filter.reset_particles(n_samples)\n",
    "particle_filter.calculate_weights_distance_wall(robot_sensor, 0.1)\n",
    "if np.isclose(np.max(particle_filter.weights), np.min(particle_filter.weights)):\n",
    "    print(f\"Possible error: The weights should not all be the same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syntax check 5 - importance sampling\n",
    "particle_filter.resample_particles()\n",
    "if not np.isclose(np.max(particle_filter.weights), np.min(particle_filter.weights)):\n",
    "    print(f\"Possible error: The weights should be set back to all the same\")\n",
    "if np.unique(particle_filter.particles, return_counts=True) == n_samples:\n",
    "    print(f\"Possible error: There probably should be duplicate particles {np.unique(particle_filter.particles, return_counts=True)} {n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syntax checks 6 and 7 - the two full updates\n",
    "particle_filter.one_full_update_door(world_ground_truth, robot_ground_truth, robot_sensor, u=0.1, z=True)\n",
    "particle_filter.one_full_update_distance(robot_ground_truth, robot_sensor, u=0.1, z=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_particle_filter_syntax(b_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"syntax_check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"not filled out\"}\n",
    "# List of URLS (creates a set)\n",
    "websites = {\"not filled out\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = -1.5\n",
    "\n",
    "# for all row, column in all_indices_from_where\n",
    "#.   if this is the column for wrist torque \n",
    "#.      print(f\"Row: {r}, Time step: {c // n_time_steps} Successful y/n: {pick_data[r, -1] == 1}, value: {pick_data[r, c]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit through gradescope, particle filter. Include just this .ipynb file and ALL of the .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(not \"not filled out\" in worked_with_names)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(not \"not filled out\" in websites)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(hours > 0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "syntax_check": {
     "name": "syntax_check",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(test_particle_filter_syntax(b_print=False))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
